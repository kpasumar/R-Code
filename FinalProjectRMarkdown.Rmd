---
title: "STAT 331 Final Project"
author: "Krishna Prem Pasumarthy & Islam Amin"
date: "`r format(Sys.Date(), format = '%B %d, %Y')`"
output:
  pdf_document:
    number_sections: yes
  html_document:
    df_print: paged
---

\section{Summary}




\section{Descriptive Statistics}

First, take a look at summary statistics of the \texttt{fhsd} dataset.

```{r echo=FALSE}
library(knitr)
suppressWarnings(library(kableExtra))
# Hide NA values from summary statistics which appear for categorical variates
options(knitr.kable.NA = '') 
fhsd <- read.csv('fhs.csv')
# summary statistics on explanatory variables broken into two small tables
kable(summary(fhsd[,1:9]), "latex", caption = "Summary Statistics", booktabs = T) %>%
kable_styling(latex_options = c("striped", "hold_position", "scale_down"))
kable(summary(fhsd[,10:18]), "latex", booktabs = T) %>%
kable_styling(latex_options = c("striped", "hold_position", "scale_down"))
```

First observation we make from the summary is that the median and average ages are around 60, which means the survey seems to have been done on a relatively old group of people. We also have a significantly higher number of females in the study, almost 30% more than the number of males. This might affect the nature of the data to be skewed towards behaviours and physical attributes associated with females.

Then take a look at \texttt{chdrisk} grouped by \texttt{sex} as well as \texttt{chdrisk} grouped by \texttt{cursmoke}.

```{r,echo=FALSE}
by(fhsd$chdrisk, fhsd$sex, summary)
by(fhsd$chdrisk, fhsd$cursmoke, summary)
```


[ADD SOME COMMENTS HERE REGARDING SUMMARY]

Now take a look at pair plots of all numeric explanatory variates i.e. variates excluding response variate \texttt{chdrisk} and logical variates such as \texttt{cursmoke}. 


```{r echo=FALSE,fig.width= 8,fig.height=8.5}
# pair plots for continuous variates
pairs(~ totchol + age + sysbp + diabp + cigpday + bmi + 
        heartrte + glucose + hdlc + ldlc, 
      col = "blue",                                         # Change color
      pch = 18,                                            # Change shape of points
      cex = 0.4,
      gap = 1,
      main = "Pair Plots of Continuous Variates",
      data = fhsd)
```

From the pair plots, we can observe a strong correlation between low density lipoprotein cholesterol and serum total cholestrol. This correlation could be explained by the fact that there could be a relationship between
the amount [TO BE CONTINUED]

Now take a look at the VIFs of these variates.


```{r echo=FALSE}
# design matrix excluding intercept
X <- model.matrix(lm(chdrisk ~ . -  1, data = fhsd))
# remove linearly dependent column (sexMale = 1 - sexFemale)
X <- X[,-1]
# calculate vif
vif <- diag(solve(cor(X)))
vif
```


[ADD COMMENTS]

\newpage

\section{Candidate Models}

\subsection{Automated Model Selection}

```{r}
suppressWarnings(library(gtools))
load_calcs = FALSE
# model with only intercept
M0 <- lm(I(logit(chdrisk)) ~ 1, data = fhsd)
Mmax <- lm(I(logit(chdrisk)) ~ (.)^2, data = fhsd)
# starting model for stepwise selection
Mstart <- lm(I(logit(chdrisk)) ~ ., data = fhsd) 
# find model coefficients which are NA
beta.max <- coef(Mmax)
names(beta.max)[is.na(beta.max)]
# find the problem with the NA coeffs
kable(table(fhsd[c("cursmoke", "cigpday")]), "latex")
kable(table(fhsd[c("bpmeds", "prevhyp")]), "latex")
# remove the coeffs with the problem and add quadratic terms for the continuous variables
Mmax <- lm(I(logit(chdrisk)) ~ (.)^2 - cursmoke:cigpday - bpmeds:prevhyp + 
             I(totchol ^ 2) + I(sysbp ^ 2) + I(diabp ^ 2) 
           + I(bmi ^ 2) + I(glucose ^ 2)
           + I(hdlc ^ 2) + I(ldlc ^ 2), data = fhsd)
anyNA(coef(Mmax)) # check if there are any remaining NAs
if(!load_calcs){
  #forward model selection
  system.time({
    Mfwd <- step(object = M0,
                  scope = list(lower = M0, upper = Mmax),
                  direction = "forward", trace = FALSE)
  })
  
  #backward model selection
  system.time({
    Mback <- step(object = Mmax,
                  scope = list(lower = M0, upper = Mmax),
                  direction = "backward", trace = FALSE)
  })
  
  #stepwise model selection
  system.time({
    Mstep <- step(object = Mstart,
                  scope = list(lower = M0, upper = Mmax),
                  direction = "both", trace = FALSE)
  })
}
# the caching/loading block
if(!load_calcs) {
  saveRDS(list(Mfwd = Mfwd, Mback = Mback, Mstep = Mstep), file = "models_automated.rds") 
} else {
  # just load the calculations
  tmp <- readRDS("models_automated.rds")
  Mfwd <- tmp$Mfwd
  Mback <- tmp$Mback
  Mstep <- tmp$Mstep
  rm(tmp) # optionally remove tmp from workspace
}
# Stepwise model selection
Mstep$call
# Forward model selection
Mfwd$call
# Backward model selection
Mback$call
beta.fwd = coef(Mfwd)
beta.back = coef(Mback)
beta.step = coef(Mstep)
identical(names(beta.fwd)[names(beta.fwd) %in% names(beta.back)], names(beta.fwd))
identical(names(beta.fwd)[names(beta.fwd) %in% names(beta.step)], names(beta.fwd))
identical(names(beta.back)[names(beta.back) %in% names(beta.step)], names(beta.back))
```


\subsection{Manual Model Selection}

```{r}
library(stringr) # For string operations
 table <- c() # Initialize empty vector
 names.table <- names(beta.step)                  # Obtain variate names in stepwise model 
 names.table <- str_remove_all(names.table,"Yes") # Remove "Yes" from interactions
 names.table <- str_remove_all(names.table,"Male") # Remove "Male"
 # Perform F-tests with Mstep by removing one variate at a time 
  for(i in names.table){
    # Obtain model without variate i
    mdl <- lm(as.formula(paste0("update(Mstep, . ~ . -", i,")")),data = fhsd)
   test <- anova(Mstep,mdl)               # F-Test between Stepwise and reduced model
   table <- cbind(table,test$`Pr(>F)`[2]) # Add corresponding p-value to the table
  }
 table <- as.data.frame(table)
 colnames(table) <- names.table            # Add appropriate column names to the table
sort(table,decreasing = TRUE)              # Arrange variates by decreasing significance
# Remove as many insignificant continuous variate interactions as possible
anova(Mstep, update(Mstep,. ~ . - cigpday:heartrte - diabp:cigpday))
#anova(Mstep, update(Mstep,. ~ . - cigpday:heartrte - diabp:cigpday -age:heartrte))
# Now remove less insignificant interactions
anova(Mstep, update(Mstep,. ~ . - cigpday:heartrte - diabp:cigpday - cigpday:heartrte 
                    - bpmeds:prevstrk))
Mmanual <- update(Mstep,. ~ . - cigpday:heartrte - diabp:cigpday - cigpday:heartrte 
                    - bpmeds:prevstrk)     # Denotes manually constructed model
```

\section{Model Diagnostics}

\subsection{Leverage and Influence Measures}

```{r}
hat1 <- hatvalues(Mstep) # Leverages of stepwise model
hat2 <- hatvalues(Mmanual)

# Should be ideally close to 1 (as in course notes)
boxplot(x = list(abs(hat1), abs(hat2)),
        ylab = "Abs. Leverages", col = c("yellow", "orange"))
plot(abs(hat1),abs(hat2)) # Nearly linear

cook1 <- cooks.distance(Mstep)
cook2 <- cooks.distance(Mmanual)

 # Values should ideally be close to zero
boxplot(x = list(abs(cook1), abs(cook2)),
        ylab = "Cooks Distances", col = c("yellow", "orange"))

```

\section{Model Selection}

\subsection{Cross Validation}

This is the written function
```{r}
library(statmod) # Load this package for using gauss.quad.prob() function
library(gtools) # Load this package for using the logit function

#' Following function calculates the mean of logit-normal distribution
#' 
#' @param mu Mean of underlying normal distribution
#' @param sigma Standard deviation of underlying normal distribution
#' 
#' @return A single number representing mean of the logit-normal distribution
#' 
#' @details The calculation of w's and g(x)'s is vectorized
logitnorm_mean <- function(mu,sigma){
  v = 1/(1+ exp(-mu))           # Value passed into both shape parameters
  alpha_1 = 1/(sigma^2 * (1-v)) # Shape parameter 1
  alpha_2 = 1/(v * sigma^2) # Shape parameter 2
  # Calculate nodes and weights for Gaussian quadrature
  gqp <- gauss.quad.prob(n = 10,dist = "beta",alpha = alpha_1,beta = alpha_2)
  x <- gqp$nodes   # Extract the nodes into a vector
  w <- gqp$weights # Similarly the weights
  # Apply the function g (defined in the project description) onto the above x's
  g <- dnorm(logit(x),mean = mu,sd = sigma,log = TRUE) - log(1-x) - 
       dbeta(x,shape1 = alpha_1,shape2 = alpha_2,log = TRUE)
  # Calculate and return the mean
  answer <- sum(w*exp(g)) 
  return(answer)
}

# For testing
mu <- c(0.7,3.2,-1.1)
sigma <- c(0.8,0.1,2.3)
sapply(1:3, function(i) logitnorm_mean(mu[i],sigma[i]))

```

```{r}
load_calcs = FALSE

# compare Mstep to Mmanual
M1 <- Mstep
M2 <- Mmanual
Mnames <- expression(M[Step], M[Manual])

# number of cross-validation replications
nreps <- 1e3

ntot <- nrow(fhsd)   # total number of observations
ntrain <- 1800       # for fitting MLE's, roughly 80% of total
ntest <- ntot-ntrain # for out-of-sample prediction

# storage space
mspe1 <- rep(NA, nreps) # mspe for M1
mspe2 <- rep(NA, nreps) # mspe for M2

if (!load_calcs){
system.time({
  for(ii in 1:nreps) {
    train.ind <- sample(ntot, ntrain) # training observations
    
    # Update the models for this training set
    M1.cv <- update(M1, subset = train.ind)
    M2.cv <- update(M2, subset = train.ind)
    
    # MLE of sigma
    M1.sigma <- sqrt(sum(resid(M1.cv)^2)/ntrain) 
    M2.sigma <- sqrt(sum(resid(M2.cv)^2)/ntrain)
    
    # predictions of logit(chdrisk) for test set
    predictions.M1 <- predict(M1.cv,newdata = fhsd[-train.ind,])
    predictions.M2 <- predict(M2.cv,newdata = fhsd[-train.ind,])
    
   # predictions of chdrisk for the test set
   values.M1 <- sapply(predictions.M1, function(i) logitnorm_mean(i,M1.sigma))
   values.M2 <- sapply(predictions.M2, function(i) logitnorm_mean(i,M2.sigma))
    
    M1.res <- fhsd$chdrisk[-train.ind] -   # test observations
              values.M1                    # prediction using training data
    M2.res <- fhsd$chdrisk[-train.ind] - values.M2
    
    # mspe for each model
    mspe1[ii] <- mean(M1.res^2)
    mspe2[ii] <- mean(M2.res^2)
    
  }
})
}

# the caching/loading block
if(!load_calcs) {
  saveRDS(list(mspe1 = mspe1,mspe2 = mspe2), file = "cross_validation_automated.rds") 
} else {
  # just load the calculations
  tmp <- readRDS("cross_validation_automated.rds")
  mspe1 <- tmp$mspe1
  mspe2 <- tmp$mspe2
  rm(tmp) # optionally remove tmp from workspace
}

# compare Root MSPEs of both the models through boxplots
boxplot(x = list(sqrt(mspe1), sqrt(mspe2)), names = Mnames,
        main = "Root MSPE",
        ylab = expression(sqrt(MSPE)),
        col = c("yellow", "orange"))

# compare predictions by training set
par(mar = c(5, 5, 2, 1))
plot(mspe1, mspe2, pch = 16,
     xlab = Mnames[1], ylab = Mnames[2],
     main = paste0("MSPE of ", Mnames[1]," vs ", Mnames[2])) # Fix this
abline(a = 0, b = 1, col= "red", lwd = 2)
```

\section{Discussion}
